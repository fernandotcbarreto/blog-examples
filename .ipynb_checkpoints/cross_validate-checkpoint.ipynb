{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemplo de cross_validate do [blog](gusrabbit.com) do Gustavo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro importamos o que vamos usar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import RidgeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos carregar os dados do dataset de breast_cancer do scikit, se você apertar **tab** depois do ponto você vai conseguir ver outros datasets que já vem no scikit. Escolhemos esse dataset pois ele só tem duas categorias e é mais simples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer = datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O scikit sempre pede pra a gente separar a variável objetivo das features, por isso já vem com essas propriedades:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cancer.data\n",
    "y = cancer.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No futuro vou subir uns exemplos de como importar e tratar arquivos csv ou xlsx de excel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos escolher um modelo para usar nesse exemplo, que tal o DummyClassifier? Ele é um classificador aleatório, nosso objetivo em qualquer classificação é ficar pelo menos melhor que ele (sim, tem como treinar um modelo pior que o aleatório : P). No scikit a gente tem que instanciar (um dia eu explico) o classificador assim:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificador_burrao = DummyClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora a variável 'classificador_burrao' tem as propriedade do DummyClassifier()! Pronto, agora vamos chamar o cross_validate. Como podemos ver na [documentação](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html) ele precisa dos parâmetros a seguir:\n",
    "\n",
    "cross_validate(estimator, X, y=None, groups=None, scoring=None, cv=None, n_jobs=1, verbose=0, fit_params=None, pre_dispatch=‘2*n_jobs’, return_train_score=’warn’)\n",
    "\n",
    "Portanto, vamos chamar ele da seguinte forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.00058603, 0.00030708, 0.00035906]),\n",
       " 'score_time': array([0.00486493, 0.00419879, 0.00733495]),\n",
       " 'test_accuracy': array([0.53157895, 0.50526316, 0.56084656]),\n",
       " 'test_average_precision': array([0.61172048, 0.65517671, 0.62575387]),\n",
       " 'test_f1': array([0.67226891, 0.65271967, 0.61802575]),\n",
       " 'test_precision': array([0.64393939, 0.57627119, 0.61206897]),\n",
       " 'test_recall': array([0.59663866, 0.52941176, 0.58823529]),\n",
       " 'test_roc_auc': array([0.49674518, 0.48698071, 0.44285714])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(classificador_burrao, X, y, return_train_score=False,\n",
    "               scoring=['accuracy',\n",
    "                        'average_precision',\n",
    "                        'f1',\n",
    "                        'precision',\n",
    "                        'recall',\n",
    "                        'roc_auc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Não vou entrar em todos os detalhes de todos o parâmetros dessa função, mas o scoring é a alma do negócio, é nele que a gente fala quais métricas a gente quer que a função retorne. Da pra ver a lista de todas as métricas do scikit [nesse link](http://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter), basta copiar e colar os nomes das métricas de classificação em uma lista, que foi o que eu fiz acima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "metricas = ['accuracy', 'average_precision', 'f1', 'precision', 'recall', 'roc_auc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por padrão, essa função vai separar o dataset em 3 partes, por isso ela devolver 3 valores para cada métrica. No futuro eu vou postar sobre Kfold e como podemos separar os dados em várias partes para fazer o cross validation como aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dessa forma, vemos que a acurácia do nosso classificador foi 52% no primeiro teste, 50% e 56% no segundo e no terceiro. É interessante pegar a média dos 3 testes, então seria uma precisão de 53% em média.\n",
    "\n",
    "Seria legal se ele já devolvesse a média direto pra a gente né? Na veradade tem outra função que faz isso, a [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html). Além disso ela ainda deixa a gente rodar várias opções de  parâmetros diferentes e retorna o melhor modelo. Vou postar sobre ela no futuro, acaba que ela é a que a gente mais usa quando ta trabalhando mesmo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bom como você viu é muito fácil fazer o cross_validate, tão fácil que agora a gente pode pegar um classificador \"de verdade\" pra comparar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = RidgeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.00080085, 0.00034523, 0.0003171 ]),\n",
       " 'score_time': array([0.00347614, 0.00404191, 0.00635886]),\n",
       " 'test_accuracy': array([0.52631579, 0.63157895, 0.47089947]),\n",
       " 'test_average_precision': array([0.63973775, 0.60963543, 0.64744377]),\n",
       " 'test_f1': array([0.59574468, 0.63374486, 0.64347826]),\n",
       " 'test_precision': array([0.61261261, 0.64516129, 0.60629921]),\n",
       " 'test_recall': array([0.68067227, 0.67226891, 0.66386555]),\n",
       " 'test_roc_auc': array([0.53751923, 0.60078116, 0.48487395])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(classificador_burrao, X, y, return_train_score=False,\n",
    "               scoring=metricas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ele tem uma acurácia média de 54%, um pouquinho melhor do que o nosso classificador aleatório. No futuro vamos dar uma olhada no significado dessas métricas e em como conseguir classificações ainda melhores. Se você rodar essa função várias vezes vai perceber que ela retorna valores diferentes, isso é por que os cortes do dataset são feitos aleatoriamente. Quando formos falar de kFold vamos ver como garantir que sempre cheguemos aos mesmos resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.53256289, 0.5429314033333333)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array([0.53157895, 0.50526316, 0.56084656]).mean(), np.array([0.52631579, 0.63157895, 0.47089947]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
