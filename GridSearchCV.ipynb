{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemplo de GridSearchCV do [blog](gusrabbit.com) do Gustavo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro importamos o que vamos usar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos carregar os dados do dataset de bosto do scikit. Esse dataset tem características e preços de casas em boston, vamos usar para fazer uma regressão! Se você apertar **tab** depois do ponto você vai conseguir ver outros datasets que já vem no scikit. Escolhemos esse dataset pois ele só tem duas categorias e é mais simples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = datasets.load_boston()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que nem da [outra vez](https://gusrabbit.com/code/cross_validate/), a gente separa a variável objetivo das features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = housing.data\n",
    "y = housing.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos pegar um modelo basicão, o DummyRegressor. Ele é um regressor cuja previsão é aleatória. É legal usar esses modelos aleatórios como baseline para comparar a qualidade dos nossos modelos. No mínino tem que ser melhor que isso. Vamos instanciar ele:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = DummyRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De acordo com a [documentação](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) ele precisa dos parâmetros a seguir:\n",
    "\n",
    "GridSearchCV(estimator, **param_grid**, **scoring=None**, fit_params=None, n_jobs=1, iid=True, refit=True, cv=None, verbose=0, pre_dispatch=‘2\\*n_jobs’, error_score=’raise’, return_train_score=’warn’)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mas primeiro! Vamos definir as métricas que queremos medir, lembrando que todas estão no [link do amor](http://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter). Vamos definir uma lista com todas as de regressão:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "metricas = ['explained_variance', 'neg_mean_absolute_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'neg_median_absolute_error', 'r2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lembrando que o tchan do Grid Search é exatamente ele fazer os cross validation de vários modelos com hiperparâmetros diferentes de uma vez. Então vamos definir o **param_grid** que vai definir quais modelos com quais parâmetros o nosso Grid Search vai rodar.\n",
    "\n",
    "Se você olhar na [documentação](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) ela diz que pode ser um dicionário ou uma lista de dicionários, qual a ideia?\n",
    "\n",
    "A vibe é definir um dicionário com os parâmetros do nosso estimador. Vamos usar o método get_params pra ver o nome certinho dos parâmetros do nosso DummyRegressor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['constant', 'quantile', 'strategy'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline.get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essas são as chaves do nosso dict, os valores são aqueles que queremos que o Grid Search rode. Criamos um dict assim:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper = {'strategy':['mean', 'median', 'quantile', 'constant'],\n",
    "         'quantile':[.75],\n",
    "         'constant':[300000]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dessa forma, o nosso Grid Search vai rodar quatro modelos, cada um com uma das estratégias. Isso acontece, pois os parâmetros quantile e constant só são usados naquelas duas estratégias. Vamos definir o Grid Search com tudo que a gente montou até agora e com *verbose=100* pra ele ir falando o que ele ta fazendo passo a passo. Vamos mandar ele fazer o refit no *neg_mean_squared_error*, mas só porque esse é a minha métricas preferida. Isso significa que ele vai escolher o modelo com o menor erro quadrado médio. E por último, a gente pede pra n retornar os scores de treinamento porque eles são meio inúteis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "meu_primeiro_grid = GridSearchCV(baseline, param_grid=hyper, scoring=metricas, verbose=100, refit='neg_mean_squared_error', return_train_score=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por padrão, essa função vai separar o dataset em 3 partes e vai devolver a métrica média de cada uma dessas 3. No futuro eu vou postar sobre Kfold e como podemos separar os dados em várias partes para fazer o cross validation como aqui. Tudo isso é controlado pelo parâmetro *cv*. Agora vamos mandar o Grid Search rodar nos dados de boston!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[CV] constant=300000, quantile=0.75, strategy=mean ...................\n",
      "[CV]  constant=300000, quantile=0.75, strategy=mean, explained_variance=0.0, neg_mean_absolute_error=-5.0932488192018, neg_mean_squared_error=-50.81033661000395, neg_mean_squared_log_error=-0.07863554756074104, neg_median_absolute_error=-3.697626112759643, r2=-0.024692018774538305, total=   0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[CV] constant=300000, quantile=0.75, strategy=mean ...................\n",
      "[CV]  constant=300000, quantile=0.75, strategy=mean, explained_variance=0.0, neg_mean_absolute_error=-9.21102312433059, neg_mean_squared_error=-154.44755358848917, neg_mean_squared_log_error=-0.1786768930506994, neg_median_absolute_error=-5.467359050445104, r2=-1.0939806689130491, total=   0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[CV] constant=300000, quantile=0.75, strategy=mean ...................\n",
      "[CV]  constant=300000, quantile=0.75, strategy=mean, explained_variance=0.0, neg_mean_absolute_error=-9.760108481262328, neg_mean_squared_error=-128.1946145801551, neg_mean_squared_log_error=-0.3627822290773284, neg_median_absolute_error=-9.95562130177515, r2=-0.9485471285713782, total=   0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[CV] constant=300000, quantile=0.75, strategy=median .................\n",
      "[CV]  constant=300000, quantile=0.75, strategy=median, explained_variance=0.0, neg_mean_absolute_error=-4.763905325443788, neg_mean_squared_error=-49.58597633136095, neg_mean_squared_log_error=-0.07274220630327113, neg_median_absolute_error=-3.0, r2=-3.459903230584871e-07, total=   0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[CV] constant=300000, quantile=0.75, strategy=median .................\n",
      "[CV]  constant=300000, quantile=0.75, strategy=median, explained_variance=0.0, neg_mean_absolute_error=-9.583431952662721, neg_mean_squared_error=-162.4073372781065, neg_mean_squared_log_error=-0.19295766710809065, neg_median_absolute_error=-5.899999999999999, r2=-1.20189842343571, total=   0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[CV] constant=300000, quantile=0.75, strategy=median .................\n",
      "[CV]  constant=300000, quantile=0.75, strategy=median, explained_variance=0.0, neg_mean_absolute_error=-8.004761904761905, neg_mean_squared_error=-97.64511904761903, neg_mean_squared_log_error=-0.2908405100680188, neg_median_absolute_error=-7.849999999999999, r2=-0.48419742094768314, total=   0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[CV] constant=300000, quantile=0.75, strategy=quantile ...............\n",
      "[CV]  constant=300000, quantile=0.75, strategy=quantile, explained_variance=0.0, neg_mean_absolute_error=-8.267455621301774, neg_mean_squared_error=-86.84650887573962, neg_mean_squared_log_error=-0.14734619627979426, neg_median_absolute_error=-8.0, r2=-0.751433476744203, total=   0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[CV] constant=300000, quantile=0.75, strategy=quantile ...............\n",
      "[CV]  constant=300000, quantile=0.75, strategy=quantile, explained_variance=0.0, neg_mean_absolute_error=-7.14792899408284, neg_mean_squared_error=-107.57656804733729, neg_mean_squared_log_error=-0.1061112025724056, neg_median_absolute_error=-4.199999999999999, r2=-0.4585096926774641, total=   0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[CV] constant=300000, quantile=0.75, strategy=quantile ...............\n",
      "[CV]  constant=300000, quantile=0.75, strategy=quantile, explained_variance=0.0, neg_mean_absolute_error=-13.01994047619048, neg_mean_squared_error=-201.95651785714284, neg_mean_squared_log_error=-0.5004445612830526, neg_median_absolute_error=-13.725000000000001, r2=-2.0697217215841475, total=   0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[CV] constant=300000, quantile=0.75, strategy=constant ...............\n",
      "[CV]  constant=300000, quantile=0.75, strategy=constant, explained_variance=-3.226308109560705e-13, neg_mean_absolute_error=-299978.2041420118, neg_mean_squared_error=-89986923009.8525, neg_mean_squared_log_error=-90.76978611874698, neg_median_absolute_error=-299979.6, r2=-1814766205.1368802, total=   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[CV] constant=300000, quantile=0.75, strategy=constant ...............\n",
      "[CV]  constant=300000, quantile=0.75, strategy=constant, explained_variance=-2.020605904817785e-13, neg_mean_absolute_error=-299971.4846153846, neg_mean_squared_error=-89982891656.1158, neg_mean_squared_log_error=-85.91131395843489, neg_median_absolute_error=-299975.0, r2=-1219976821.4418595, total=   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s remaining:    0.0s\n",
      "[CV] constant=300000, quantile=0.75, strategy=constant ...............\n",
      "[CV]  constant=300000, quantile=0.75, strategy=constant, explained_variance=8.72635297355373e-14, neg_mean_absolute_error=-299982.74404761905, neg_mean_squared_error=-89989646792.12917, neg_mean_squared_log_error=-96.03766157610265, neg_median_absolute_error=-299983.65, r2=-1367834899.33676, total=   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=DummyRegressor(constant=None, quantile=None, strategy='mean'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'strategy': ['mean', 'median', 'quantile', 'constant'], 'quantile': [0.75], 'constant': [300000]},\n",
       "       pre_dispatch='2*n_jobs', refit='neg_mean_squared_error',\n",
       "       return_train_score=False,\n",
       "       scoring=['explained_variance', 'neg_mean_absolute_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'neg_median_absolute_error', 'r2'],\n",
       "       verbose=100)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meu_primeiro_grid.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos dar uma olhada nos resultados, o melhor estimador foi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyRegressor(constant=300000, quantile=0.75, strategy='median')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meu_primeiro_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E o melhor score foi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-103.223814229249"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meu_primeiro_grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que diabéisso? Ok, como a gente colocou *neg_mean_squared_error* no refite ele está devolvendo o melhor score dessa métrica. Essa métrica da a média do quadrado dos erros, só q negativa. Por que negativa? Acho que é pra ficar mais fácil de minimizar, aí eles adotam o padrão de colocar as métricas tudo negativa. O erro é a diferença entre o que o modelo preveu e o valor verdadeiro da casa. Aqui como a melhor estratégia foi a mediana, a previsão do modelo foi a mediana dos valores de treinamento pra toda casa nova. A gente pega a diferença do prebisto pelo verdadeiro, eleva ao quadrado (normal em estatística pra evitar que erros negativos e positivos se anulem, e é mais fácil de derivar do que usar módeulo).\n",
    "\n",
    "Então pra ter uma ideia se isso ta bom ou ruim basta tirar a raiz disso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.159912117201063"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(meu_primeiro_grid.best_score_*-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em média nosso modelo errou o preço por 10 mil dólares. O Grid Search retorna um dicionário com todos os resultados, eu gosto de transformar ele num dataframe pra ficar mais fácil de ver (antes vou usar uma manhã do pandas pra que ele mostre todas as colunas):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_explained_variance</th>\n",
       "      <th>mean_test_neg_mean_absolute_error</th>\n",
       "      <th>mean_test_neg_mean_squared_error</th>\n",
       "      <th>mean_test_neg_mean_squared_log_error</th>\n",
       "      <th>mean_test_neg_median_absolute_error</th>\n",
       "      <th>mean_test_r2</th>\n",
       "      <th>param_constant</th>\n",
       "      <th>param_quantile</th>\n",
       "      <th>param_strategy</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_explained_variance</th>\n",
       "      <th>rank_test_neg_mean_absolute_error</th>\n",
       "      <th>rank_test_neg_mean_squared_error</th>\n",
       "      <th>rank_test_neg_mean_squared_log_error</th>\n",
       "      <th>rank_test_neg_median_absolute_error</th>\n",
       "      <th>rank_test_r2</th>\n",
       "      <th>split0_test_explained_variance</th>\n",
       "      <th>split0_test_neg_mean_absolute_error</th>\n",
       "      <th>split0_test_neg_mean_squared_error</th>\n",
       "      <th>split0_test_neg_mean_squared_log_error</th>\n",
       "      <th>split0_test_neg_median_absolute_error</th>\n",
       "      <th>split0_test_r2</th>\n",
       "      <th>split1_test_explained_variance</th>\n",
       "      <th>split1_test_neg_mean_absolute_error</th>\n",
       "      <th>split1_test_neg_mean_squared_error</th>\n",
       "      <th>split1_test_neg_mean_squared_log_error</th>\n",
       "      <th>split1_test_neg_median_absolute_error</th>\n",
       "      <th>split1_test_r2</th>\n",
       "      <th>split2_test_explained_variance</th>\n",
       "      <th>split2_test_neg_mean_absolute_error</th>\n",
       "      <th>split2_test_neg_mean_squared_error</th>\n",
       "      <th>split2_test_neg_mean_squared_log_error</th>\n",
       "      <th>split2_test_neg_median_absolute_error</th>\n",
       "      <th>split2_test_r2</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_explained_variance</th>\n",
       "      <th>std_test_neg_mean_absolute_error</th>\n",
       "      <th>std_test_neg_mean_squared_error</th>\n",
       "      <th>std_test_neg_mean_squared_log_error</th>\n",
       "      <th>std_test_neg_median_absolute_error</th>\n",
       "      <th>std_test_r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000671</td>\n",
       "      <td>0.002539</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-8.018024</td>\n",
       "      <td>-1.111172e+02</td>\n",
       "      <td>-0.206390</td>\n",
       "      <td>-6.366456</td>\n",
       "      <td>-6.885605e-01</td>\n",
       "      <td>300000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>mean</td>\n",
       "      <td>{'constant': 300000, 'quantile': 0.75, 'strate...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-5.093249</td>\n",
       "      <td>-5.081034e+01</td>\n",
       "      <td>-0.078636</td>\n",
       "      <td>-3.697626</td>\n",
       "      <td>-2.469202e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-9.211023</td>\n",
       "      <td>-1.544476e+02</td>\n",
       "      <td>-0.178677</td>\n",
       "      <td>-5.467359</td>\n",
       "      <td>-1.093981e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-9.760108</td>\n",
       "      <td>-1.281946e+02</td>\n",
       "      <td>-0.362782</td>\n",
       "      <td>-9.955621</td>\n",
       "      <td>-9.485471e-01</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.001006</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.083278</td>\n",
       "      <td>4.402961e+01</td>\n",
       "      <td>0.117594</td>\n",
       "      <td>2.631723</td>\n",
       "      <td>4.738525e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000743</td>\n",
       "      <td>0.001875</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-7.449605</td>\n",
       "      <td>-1.032238e+02</td>\n",
       "      <td>-0.185305</td>\n",
       "      <td>-5.578854</td>\n",
       "      <td>-5.621859e-01</td>\n",
       "      <td>300000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>median</td>\n",
       "      <td>{'constant': 300000, 'quantile': 0.75, 'strate...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-4.763905</td>\n",
       "      <td>-4.958598e+01</td>\n",
       "      <td>-0.072742</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-3.459903e-07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-9.583432</td>\n",
       "      <td>-1.624073e+02</td>\n",
       "      <td>-0.192958</td>\n",
       "      <td>-5.900000</td>\n",
       "      <td>-1.201898e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-8.004762</td>\n",
       "      <td>-9.764512e+01</td>\n",
       "      <td>-0.290841</td>\n",
       "      <td>-7.850000</td>\n",
       "      <td>-4.841974e-01</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.008020</td>\n",
       "      <td>4.627207e+01</td>\n",
       "      <td>0.089159</td>\n",
       "      <td>1.992041</td>\n",
       "      <td>4.942254e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001881</td>\n",
       "      <td>0.002124</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-9.471443</td>\n",
       "      <td>-1.319885e+02</td>\n",
       "      <td>-0.250808</td>\n",
       "      <td>-8.631621</td>\n",
       "      <td>-1.091292e+00</td>\n",
       "      <td>300000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>quantile</td>\n",
       "      <td>{'constant': 300000, 'quantile': 0.75, 'strate...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-8.267456</td>\n",
       "      <td>-8.684651e+01</td>\n",
       "      <td>-0.147346</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>-7.514335e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-7.147929</td>\n",
       "      <td>-1.075766e+02</td>\n",
       "      <td>-0.106111</td>\n",
       "      <td>-4.200000</td>\n",
       "      <td>-4.585097e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-13.019940</td>\n",
       "      <td>-2.019565e+02</td>\n",
       "      <td>-0.500445</td>\n",
       "      <td>-13.725000</td>\n",
       "      <td>-2.069722e+00</td>\n",
       "      <td>0.001280</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.543220</td>\n",
       "      <td>5.005038e+01</td>\n",
       "      <td>0.176801</td>\n",
       "      <td>3.912279</td>\n",
       "      <td>7.001137e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>-1.462699e-13</td>\n",
       "      <td>-299977.467194</td>\n",
       "      <td>-8.998648e+10</td>\n",
       "      <td>-90.896113</td>\n",
       "      <td>-299979.408300</td>\n",
       "      <td>-1.467723e+09</td>\n",
       "      <td>300000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>constant</td>\n",
       "      <td>{'constant': 300000, 'quantile': 0.75, 'strate...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-3.226308e-13</td>\n",
       "      <td>-299978.204142</td>\n",
       "      <td>-8.998692e+10</td>\n",
       "      <td>-90.769786</td>\n",
       "      <td>-299979.600000</td>\n",
       "      <td>-1.814766e+09</td>\n",
       "      <td>-2.020606e-13</td>\n",
       "      <td>-299971.484615</td>\n",
       "      <td>-8.998289e+10</td>\n",
       "      <td>-85.911314</td>\n",
       "      <td>-299975.000000</td>\n",
       "      <td>-1.219977e+09</td>\n",
       "      <td>8.726353e-14</td>\n",
       "      <td>-299982.744048</td>\n",
       "      <td>-8.998965e+10</td>\n",
       "      <td>-96.037662</td>\n",
       "      <td>-299983.650000</td>\n",
       "      <td>-1.367835e+09</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>1.718582e-13</td>\n",
       "      <td>4.623897</td>\n",
       "      <td>2.774121e+06</td>\n",
       "      <td>4.132971</td>\n",
       "      <td>3.532197</td>\n",
       "      <td>2.530577e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_explained_variance  \\\n",
       "0       0.000671         0.002539                  0.000000e+00   \n",
       "1       0.000743         0.001875                  0.000000e+00   \n",
       "2       0.001881         0.002124                  0.000000e+00   \n",
       "3       0.000403         0.001779                 -1.462699e-13   \n",
       "\n",
       "   mean_test_neg_mean_absolute_error  mean_test_neg_mean_squared_error  \\\n",
       "0                          -8.018024                     -1.111172e+02   \n",
       "1                          -7.449605                     -1.032238e+02   \n",
       "2                          -9.471443                     -1.319885e+02   \n",
       "3                     -299977.467194                     -8.998648e+10   \n",
       "\n",
       "   mean_test_neg_mean_squared_log_error  mean_test_neg_median_absolute_error  \\\n",
       "0                             -0.206390                            -6.366456   \n",
       "1                             -0.185305                            -5.578854   \n",
       "2                             -0.250808                            -8.631621   \n",
       "3                            -90.896113                       -299979.408300   \n",
       "\n",
       "   mean_test_r2 param_constant param_quantile param_strategy  \\\n",
       "0 -6.885605e-01         300000           0.75           mean   \n",
       "1 -5.621859e-01         300000           0.75         median   \n",
       "2 -1.091292e+00         300000           0.75       quantile   \n",
       "3 -1.467723e+09         300000           0.75       constant   \n",
       "\n",
       "                                              params  \\\n",
       "0  {'constant': 300000, 'quantile': 0.75, 'strate...   \n",
       "1  {'constant': 300000, 'quantile': 0.75, 'strate...   \n",
       "2  {'constant': 300000, 'quantile': 0.75, 'strate...   \n",
       "3  {'constant': 300000, 'quantile': 0.75, 'strate...   \n",
       "\n",
       "   rank_test_explained_variance  rank_test_neg_mean_absolute_error  \\\n",
       "0                             1                                  2   \n",
       "1                             1                                  1   \n",
       "2                             1                                  3   \n",
       "3                             4                                  4   \n",
       "\n",
       "   rank_test_neg_mean_squared_error  rank_test_neg_mean_squared_log_error  \\\n",
       "0                                 2                                     2   \n",
       "1                                 1                                     1   \n",
       "2                                 3                                     3   \n",
       "3                                 4                                     4   \n",
       "\n",
       "   rank_test_neg_median_absolute_error  rank_test_r2  \\\n",
       "0                                    2             2   \n",
       "1                                    1             1   \n",
       "2                                    3             3   \n",
       "3                                    4             4   \n",
       "\n",
       "   split0_test_explained_variance  split0_test_neg_mean_absolute_error  \\\n",
       "0                    0.000000e+00                            -5.093249   \n",
       "1                    0.000000e+00                            -4.763905   \n",
       "2                    0.000000e+00                            -8.267456   \n",
       "3                   -3.226308e-13                       -299978.204142   \n",
       "\n",
       "   split0_test_neg_mean_squared_error  split0_test_neg_mean_squared_log_error  \\\n",
       "0                       -5.081034e+01                               -0.078636   \n",
       "1                       -4.958598e+01                               -0.072742   \n",
       "2                       -8.684651e+01                               -0.147346   \n",
       "3                       -8.998692e+10                              -90.769786   \n",
       "\n",
       "   split0_test_neg_median_absolute_error  split0_test_r2  \\\n",
       "0                              -3.697626   -2.469202e-02   \n",
       "1                              -3.000000   -3.459903e-07   \n",
       "2                              -8.000000   -7.514335e-01   \n",
       "3                         -299979.600000   -1.814766e+09   \n",
       "\n",
       "   split1_test_explained_variance  split1_test_neg_mean_absolute_error  \\\n",
       "0                    0.000000e+00                            -9.211023   \n",
       "1                    0.000000e+00                            -9.583432   \n",
       "2                    0.000000e+00                            -7.147929   \n",
       "3                   -2.020606e-13                       -299971.484615   \n",
       "\n",
       "   split1_test_neg_mean_squared_error  split1_test_neg_mean_squared_log_error  \\\n",
       "0                       -1.544476e+02                               -0.178677   \n",
       "1                       -1.624073e+02                               -0.192958   \n",
       "2                       -1.075766e+02                               -0.106111   \n",
       "3                       -8.998289e+10                              -85.911314   \n",
       "\n",
       "   split1_test_neg_median_absolute_error  split1_test_r2  \\\n",
       "0                              -5.467359   -1.093981e+00   \n",
       "1                              -5.900000   -1.201898e+00   \n",
       "2                              -4.200000   -4.585097e-01   \n",
       "3                         -299975.000000   -1.219977e+09   \n",
       "\n",
       "   split2_test_explained_variance  split2_test_neg_mean_absolute_error  \\\n",
       "0                    0.000000e+00                            -9.760108   \n",
       "1                    0.000000e+00                            -8.004762   \n",
       "2                    0.000000e+00                           -13.019940   \n",
       "3                    8.726353e-14                       -299982.744048   \n",
       "\n",
       "   split2_test_neg_mean_squared_error  split2_test_neg_mean_squared_log_error  \\\n",
       "0                       -1.281946e+02                               -0.362782   \n",
       "1                       -9.764512e+01                               -0.290841   \n",
       "2                       -2.019565e+02                               -0.500445   \n",
       "3                       -8.998965e+10                              -96.037662   \n",
       "\n",
       "   split2_test_neg_median_absolute_error  split2_test_r2  std_fit_time  \\\n",
       "0                              -9.955621   -9.485471e-01      0.000227   \n",
       "1                              -7.850000   -4.841974e-01      0.000097   \n",
       "2                             -13.725000   -2.069722e+00      0.001280   \n",
       "3                         -299983.650000   -1.367835e+09      0.000248   \n",
       "\n",
       "   std_score_time  std_test_explained_variance  \\\n",
       "0        0.001006                 0.000000e+00   \n",
       "1        0.000262                 0.000000e+00   \n",
       "2        0.001010                 0.000000e+00   \n",
       "3        0.000239                 1.718582e-13   \n",
       "\n",
       "   std_test_neg_mean_absolute_error  std_test_neg_mean_squared_error  \\\n",
       "0                          2.083278                     4.402961e+01   \n",
       "1                          2.008020                     4.627207e+01   \n",
       "2                          2.543220                     5.005038e+01   \n",
       "3                          4.623897                     2.774121e+06   \n",
       "\n",
       "   std_test_neg_mean_squared_log_error  std_test_neg_median_absolute_error  \\\n",
       "0                             0.117594                            2.631723   \n",
       "1                             0.089159                            1.992041   \n",
       "2                             0.176801                            3.912279   \n",
       "3                             4.132971                            3.532197   \n",
       "\n",
       "    std_test_r2  \n",
       "0  4.738525e-01  \n",
       "1  4.942254e-01  \n",
       "2  7.001137e-01  \n",
       "3  2.530577e+08  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('max_columns',200)\n",
    "pd.DataFrame(meu_primeiro_grid.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos ver se uma regressão linear simples fica melhor? Bora instanciar!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['copy_X', 'fit_intercept', 'n_jobs', 'normalize'])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ols.get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os únicos parâmetros interessantes para a gente são o *fit_intercept* e o *normalize*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_params = {'fit_intercept':[True, False],\n",
    "              'normalize':[True, False]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos definir o Grid Search!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "meu_segundo_grid = GridSearchCV(ols, param_grid=ols_params, scoring=metricas, verbose=100, refit='neg_mean_squared_error', return_train_score=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[CV] fit_intercept=True, normalize=True ..............................\n",
      "[CV]  fit_intercept=True, normalize=True, explained_variance=0.5970136165050308, neg_mean_absolute_error=-3.3288087161058484, neg_mean_squared_error=-20.68720738696552, neg_mean_squared_log_error=-0.08111839971788834, neg_median_absolute_error=-2.3841241723561346, r2=0.58280110476608, total=   0.1s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[CV] fit_intercept=True, normalize=True ..............................\n",
      "[CV]  fit_intercept=True, normalize=True, explained_variance=0.541285783038106, neg_mean_absolute_error=-4.282203356265531, neg_mean_squared_error=-34.52324169521958, neg_mean_squared_log_error=-0.034322552052381425, neg_median_absolute_error=-3.152069451528778, r2=0.531938194821685, total=   0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[CV] fit_intercept=True, normalize=True ..............................\n",
      "[CV]  fit_intercept=True, normalize=True, explained_variance=-4.245830607570933, neg_mean_absolute_error=-13.404003531501544, neg_mean_squared_error=-450.7295117354292, neg_mean_squared_log_error=-0.7939643280767945, neg_median_absolute_error=-8.591224772296416, r2=-5.851049856741862, total=   0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n",
      "[CV] fit_intercept=True, normalize=False .............................\n",
      "[CV]  fit_intercept=True, normalize=False, explained_variance=0.5970136165050319, neg_mean_absolute_error=-3.328808716105844, neg_mean_squared_error=-20.68720738696547, neg_mean_squared_log_error=-0.0811183997178884, neg_median_absolute_error=-2.3841241723561915, r2=0.5828011047660812, total=   0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n",
      "[CV] fit_intercept=True, normalize=False .............................\n",
      "[CV]  fit_intercept=True, normalize=False, explained_variance=0.541285783038105, neg_mean_absolute_error=-4.282203356265536, neg_mean_squared_error=-34.52324169521964, neg_mean_squared_log_error=-0.03432255205238151, neg_median_absolute_error=-3.1520694515287317, r2=0.5319381948216843, total=   0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s remaining:    0.0s\n",
      "[CV] fit_intercept=True, normalize=False .............................\n",
      "[CV]  fit_intercept=True, normalize=False, explained_variance=-4.245830607570747, neg_mean_absolute_error=-13.404003531501333, neg_mean_squared_error=-450.7295117354122, neg_mean_squared_log_error=-0.7939643280768705, neg_median_absolute_error=-8.59122477229633, r2=-5.8510498567416045, total=   0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[CV] fit_intercept=False, normalize=True .............................\n",
      "[CV]  fit_intercept=False, normalize=True, explained_variance=0.6296771626432986, neg_mean_absolute_error=-3.160259851660147, neg_mean_squared_error=-18.44803992125606, neg_mean_squared_log_error=-0.050357306076230096, neg_median_absolute_error=-2.290322960665371, r2=0.6279583933001682, total=   0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[CV] fit_intercept=False, normalize=True .............................\n",
      "[CV]  fit_intercept=False, normalize=True, explained_variance=0.6151652774392933, neg_mean_absolute_error=-4.245529369305763, neg_mean_squared_error=-36.74203250349901, neg_mean_squared_log_error=-0.03571711998263256, neg_median_absolute_error=-2.530601091431972, r2=0.5018561057697717, total=   0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
      "[CV] fit_intercept=False, normalize=True .............................\n",
      "[CV]  fit_intercept=False, normalize=True, explained_variance=-4.57284461766454, neg_mean_absolute_error=-13.69199436543777, neg_mean_squared_error=-476.8086512457138, neg_mean_squared_log_error=-0.6688105981773506, neg_median_absolute_error=-8.711737243383224, r2=-6.247450536870309, total=   0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s remaining:    0.0s\n",
      "[CV] fit_intercept=False, normalize=False ............................\n",
      "[CV]  fit_intercept=False, normalize=False, explained_variance=0.6296771626432986, neg_mean_absolute_error=-3.160259851660147, neg_mean_squared_error=-18.44803992125606, neg_mean_squared_log_error=-0.050357306076230096, neg_median_absolute_error=-2.290322960665371, r2=0.6279583933001682, total=   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.1s remaining:    0.0s\n",
      "[CV] fit_intercept=False, normalize=False ............................\n",
      "[CV]  fit_intercept=False, normalize=False, explained_variance=0.6151652774392933, neg_mean_absolute_error=-4.245529369305763, neg_mean_squared_error=-36.74203250349901, neg_mean_squared_log_error=-0.03571711998263256, neg_median_absolute_error=-2.530601091431972, r2=0.5018561057697717, total=   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s remaining:    0.0s\n",
      "[CV] fit_intercept=False, normalize=False ............................\n",
      "[CV]  fit_intercept=False, normalize=False, explained_variance=-4.57284461766454, neg_mean_absolute_error=-13.69199436543777, neg_mean_squared_error=-476.8086512457138, neg_mean_squared_log_error=-0.6688105981773506, neg_median_absolute_error=-8.711737243383224, r2=-6.247450536870309, total=   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'fit_intercept': [True, False], 'normalize': [True, False]},\n",
       "       pre_dispatch='2*n_jobs', refit='neg_mean_squared_error',\n",
       "       return_train_score=False,\n",
       "       scoring=['explained_variance', 'neg_mean_absolute_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'neg_median_absolute_error', 'r2'],\n",
       "       verbose=100)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meu_segundo_grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meu_segundo_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-168.08917760165718"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meu_segundo_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.964921041088418"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(meu_segundo_grid.best_score_*-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A regressão ta dando um erro de 12!!! Pior do que sempre chutar a mediana! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
